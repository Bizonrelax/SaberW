Я выполнил п.1 Ошибки.
___
п.2
сделал.
п. 3
сделал
п.4 - заменил
Ошибки:
```
Description	Resource	Path	Location	Type
dictionary cannot be resolved to a variable	SaberWCompressor.java	/SaberW/src/com/saberw/core	line 100	Java Problem
dictionary cannot be resolved	SaberWCompressor.java	/SaberW/src/com/saberw/core	line 97	Java Problem
allCandidates cannot be resolved to a variable	SaberWCompressor.java	/SaberW/src/com/saberw/core	line 64	Java Problem
```
Фрагменты кода:
```
allCandidatesWithCodes.addAll(wordCandidatesList);

allCandidatesWithCodes.addAll(phraseCandidatesList);

// 8. Кодирование текста: сначала заменяем слова, потом фразы

String compressedText = encodeTextWithPriority(text, wordCandidatesList, phraseCandidatesList);

// 9. Подсчёт статистики

CompressionResult.Statistics stats = new CompressionResult.Statistics(

text.length(),

compressedText.length(),

dictionary.size()

);

return new CompressionResult(compressedText, dictionary, stats);

}

// НОВЫЙ МЕТОД: Кодирование текста с учетом фраз

private String encodeText(String text, List<Candidate> candidates) {

// Сортируем кандидатов по убыванию длины текста

// Это важно: сначала заменяем самые длинные фразы

candidates.sort((a, b) ->
```
ещё:
```
return compress(text, 2, 5, 7); // мин. частота = 2, макс. токенов во фразе = 5, мин. длина фразы = 7

}

public CompressionResult compress(String text, int minFrequency,

int maxPhraseTokens, int minPhraseLength) {

if (text == null || text.isEmpty()) {

return new CompressionResult("", Collections.emptyList(),

new CompressionResult.Statistics(0, 0, 0));

}

// Проверяем наличие специальных символов

if (ValidationHelper.containsSpecialCharacters(text)) {

System.err.println("Warning: Text contains special SaberW characters. " +

"Consider escaping them.");

}

// 1. Токенизация

Tokenizer tokenizer = new Tokenizer();

List<Token> tokens = tokenizer.tokenize(text);

// 2. Анализ частотности слов

Map<String, Integer> wordFrequency = new HashMap<>();

for (Token token : tokens) {

if (token.isWord() && ValidationHelper.shouldEncodeWord(token.getValue())) {

String word = token.getValue();

wordFrequency.put(word, wordFrequency.getOrDefault(word, 0) + 1);

}

}

// 3. Создание кандидатов для слов

List<Candidate> wordCandidates = new ArrayList<>();

for (Map.Entry<String, Integer> entry : wordFrequency.entrySet()) {

if (entry.getValue() >= minFrequency) {

wordCandidates.add(new Candidate(entry.getKey(), entry.getValue()));

}

}

// 4. Поиск фраз-кандидатов

List<Candidate> phraseCandidates = tokenizer.findPhraseCandidates(

tokens, maxPhraseTokens, minFrequency, minPhraseLength);

// 5. Раздельная обработка: сначала слова, потом фразы

List<Candidate> wordCandidatesList = new ArrayList<>();

List<Candidate> phraseCandidatesList = new ArrayList<>();

for (Candidate candidate : allCandidates) {

// Проверяем, является ли кандидат фразой (содержит пробелы или пунктуацию)

if (candidate.getText().matches(".*[\\s\\p{Punct}].*")) {

phraseCandidatesList.add(candidate);

} else {

wordCandidatesList.add(candidate);

}

}
```